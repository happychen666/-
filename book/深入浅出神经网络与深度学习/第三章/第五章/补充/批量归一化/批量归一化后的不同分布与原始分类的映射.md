批量归一化后的不同分布与原始分类的映射，实际上通过神经网络中的**学习过程**来完成。网络通过训练数据学习到合适的**权重**和**偏置**，以便恢复归一化前的分类信息。为了说明这一点，我们可以用简单的例子来展示批量归一化如何影响神经网络的分类。

### 核心思想

批量归一化调整了中间层的激活值，使得每一层的输入分布稳定，但它并没有改变模型的最终分类能力。模型通过学习参数 \(\gamma\) 和 \(\beta\) 恢复必要的分布，从而实现正确的分类。为了更好地理解这一点，接下来分两步解释：

1. **归一化与分布映射的过程**
2. **为什么通过缩放和偏移不会丢失分类能力**

### 1. 归一化与分布映射的过程

假设神经网络的某一层的输入是未经批量归一化的。我们继续用之前的例子，假设两个类别的数据在一个特征维度上的值如下：

- 类别 1：\( h_1 = [50, 52, 54, 56] \)
- 类别 2：\( h_2 = [2, 4, 6, 8] \)

这些数据直接传入神经网络，经过权重和偏置运算后，神经网络会学到不同的权重来将不同类别的数据映射到不同的输出空间，使得最终的分类结果正确。

但是，在**批量归一化**之后，输入数据变成了标准正态分布：

- 归一化后，类别1的数据：\( \hat{h}_1 \approx [-1.34, -0.45, 0.45, 1.34] \)
- 归一化后，类别2的数据：\( \hat{h}_2 \approx [-1.34, -0.45, 0.45, 1.34] \)

由于归一化后的两个类别的数据分布变得完全相同，网络无法直接区分它们。此时，**需要缩放和偏移**来帮助网络区分归一化后的数据，并映射回原始的分类信息。

### 2. 缩放和偏移如何帮助恢复分类能力

批量归一化后，神经网络通过可学习参数 \(\gamma\) 和 \(\beta\) 对归一化后的数据进行调整。这两个参数是网络**自动学习到的**，用于恢复每个特征的适当范围和中心。具体来说：

- \(\gamma\) 控制特征的缩放（放大或缩小某个特征的值）
- \(\beta\) 控制特征的偏移（改变某个特征的值的整体位置）

通过这些调整，网络可以重新调整每个特征的分布，使得它们更适合模型的分类任务。

#### 举例说明

假设在训练中，网络学习到以下缩放和平移参数：

- 类别1的 \(\gamma_1 = 5\), \(\beta_1 = 10\)
- 类别2的 \(\gamma_2 = 2\), \(\beta_2 = 3\)

1. 对类别1的数据进行缩放和偏移：
   \[
   h_{BN_1} = \gamma_1 \cdot \hat{h}_1 + \beta_1 = 5 \cdot [-1.34, -0.45, 0.45, 1.34] + 10 \approx [3.3, 7.75, 12.25, 16.7]
   \]
   现在，类别1的数据重新映射到原始的较大范围。

2. 对类别2的数据进行缩放和偏移：
   \[
   h_{BN_2} = \gamma_2 \cdot \hat{h}_2 + \beta_2 = 2 \cdot [-1.34, -0.45, 0.45, 1.34] + 3 \approx [0.32, 2.1, 3.9, 5.68]
   \]
   类别2的数据映射到了一个较小的范围。

#### 恢复分类映射

尽管经过归一化后类别1和类别2的数据初始分布完全相同，但通过可学习的 \(\gamma\) 和 \(\beta\)，网络可以重新调整数据的分布范围，使得每一类的数据回到它们原本具有区分度的范围。因此，分类任务可以在经过训练的网络中继续正确进行。

- 类别1经过缩放和平移后，数据范围是 \( [3.3, 16.7] \)
- 类别2经过缩放和平移后，数据范围是 \( [0.32, 5.68] \)

这样，不同的类别被调整到不同的范围，网络可以利用这些不同的特征分布来区分它们。

### 为什么缩放和平移不会损失表达能力？

如果没有 \(\gamma\) 和 \(\beta\)，数据的分布会被固定在一个标准正态分布范围，导致原始数据的区分度丢失。通过**可学习的** \(\gamma\) 和 \(\beta\)，网络可以将不同类别的数据分布调整到原来的区间，甚至更适合分类任务的区间，从而确保**批量归一化不会影响模型的表示能力**。

### 总结

- **批量归一化**将数据归一化为均值为0、方差为1的标准正态分布，可能导致模型丧失原始数据的分布信息。
- **缩放和平移参数 \(\gamma\) 和 \(\beta\)** 能够将标准化后的数据恢复到适合分类的分布，确保模型保留甚至增强了表示能力。
- 经过训练，网络会学习到最优的 \(\gamma\) 和 \(\beta\)，将每类数据调整到不同的范围，确保它们可以映射回原始的分类信息。
